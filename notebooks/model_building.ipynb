{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_faults = pd.read_pickle('../data/on_faults.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_faults = on_faults[on_faults['active'] == True]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need all readouts of codes other than the breakdown down within a time period of 1 week before the breakdown code occured. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE will have to get some sort of aggregate of events occuring up to the derate and then make new binary features of weather or not they occured. Then our result is whether or not the truck derates.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column of the df will be time periods:\n",
    "\n",
    "7-6 days prior total # of non derate codes (ie not 5246)\n",
    "\n",
    "6-5 '''\n",
    "\n",
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = pd.Timedelta('1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = on_faults.set_index('EventTimeStamp').sort_index(ascending = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make dummy columns for category of spn, get_dummies function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.get_dummies(data = df, columns =['spn'])\n",
    "        .filter(regex='^(spn|EquipmentID)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derate_times = df[df['spn_5246'] == 1][['EquipmentID', 'spn_5246']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_dict = {col: 'sum' for col in df.columns if (col != 'EquipmentID')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_dict['EquipmentID'] = lambda x : x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling = (df\n",
    "            .groupby(by = 'EquipmentID')\n",
    "            .rolling(window = '1D')\n",
    "            .sum()         \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EquipmentID  EventTimeStamp     \n",
       "1452         2016-02-09 15:24:56    5.0\n",
       "1535         2016-01-11 12:12:52    5.0\n",
       "             2016-01-11 12:12:53    5.0\n",
       "1528         2017-02-25 07:30:09    5.0\n",
       "             2017-02-25 07:30:09    5.0\n",
       "                                   ... \n",
       "1610         2017-11-06 09:04:06    0.0\n",
       "             2017-11-06 11:02:00    0.0\n",
       "             2017-11-06 14:00:59    0.0\n",
       "             2017-11-06 14:39:33    0.0\n",
       "R1764        2015-02-25 06:08:43    0.0\n",
       "Name: spn_5246, Length: 548848, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolling['spn_5246'].sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 column ID for nth derate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = rolling[rolling['spn_5246'] <= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    546450\n",
       "1.0      1867\n",
       "Name: spn_5246, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data['spn_5246'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2000\n",
       "1.0    1867\n",
       "Name: spn_5246, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.utils import resample\n",
    "# Separate majority and minority classes\n",
    "df_majority = ml_data[ml_data.spn_5246==0]\n",
    "df_minority = ml_data[ml_data.spn_5246==1]\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=2000,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled.spn_5246.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_downsampled.drop(columns='spn_5246')\n",
    "\n",
    "y = df_downsampled['spn_5246']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.25, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:37<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "RandomForestClassifier             0.95               0.95     0.95      0.95   \n",
      "BaggingClassifier                  0.95               0.95     0.95      0.95   \n",
      "ExtraTreesClassifier               0.95               0.95     0.95      0.95   \n",
      "ExtraTreeClassifier                0.94               0.94     0.94      0.94   \n",
      "DecisionTreeClassifier             0.93               0.93     0.93      0.93   \n",
      "KNeighborsClassifier               0.93               0.93     0.93      0.93   \n",
      "XGBClassifier                      0.92               0.92     0.92      0.92   \n",
      "LGBMClassifier                     0.92               0.92     0.92      0.92   \n",
      "AdaBoostClassifier                 0.92               0.92     0.92      0.92   \n",
      "LabelSpreading                     0.92               0.91     0.91      0.91   \n",
      "LabelPropagation                   0.91               0.91     0.91      0.91   \n",
      "LogisticRegression                 0.91               0.91     0.91      0.91   \n",
      "CalibratedClassifierCV             0.90               0.90     0.90      0.90   \n",
      "LinearSVC                          0.90               0.90     0.90      0.90   \n",
      "SGDClassifier                      0.89               0.89     0.89      0.89   \n",
      "Perceptron                         0.89               0.89     0.89      0.89   \n",
      "BernoulliNB                        0.89               0.89     0.89      0.89   \n",
      "SVC                                0.89               0.88     0.88      0.89   \n",
      "NuSVC                              0.87               0.86     0.86      0.87   \n",
      "RidgeClassifier                    0.87               0.86     0.86      0.86   \n",
      "RidgeClassifierCV                  0.87               0.86     0.86      0.86   \n",
      "LinearDiscriminantAnalysis         0.86               0.86     0.86      0.86   \n",
      "PassiveAggressiveClassifier        0.80               0.81     0.81      0.80   \n",
      "NearestCentroid                    0.80               0.79     0.79      0.79   \n",
      "QuadraticDiscriminantAnalysis      0.57               0.59     0.59      0.49   \n",
      "GaussianNB                         0.53               0.56     0.56      0.42   \n",
      "DummyClassifier                    0.53               0.50     0.50      0.37   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "RandomForestClassifier               1.32  \n",
      "BaggingClassifier                    0.58  \n",
      "ExtraTreesClassifier                 1.62  \n",
      "ExtraTreeClassifier                  0.10  \n",
      "DecisionTreeClassifier               0.16  \n",
      "KNeighborsClassifier                 0.26  \n",
      "XGBClassifier                        8.04  \n",
      "LGBMClassifier                       1.30  \n",
      "AdaBoostClassifier                   1.05  \n",
      "LabelSpreading                       0.99  \n",
      "LabelPropagation                     0.87  \n",
      "LogisticRegression                   0.30  \n",
      "CalibratedClassifierCV               9.01  \n",
      "LinearSVC                            2.36  \n",
      "SGDClassifier                        0.33  \n",
      "Perceptron                           0.18  \n",
      "BernoulliNB                          0.13  \n",
      "SVC                                  2.56  \n",
      "NuSVC                                3.79  \n",
      "RidgeClassifier                      0.14  \n",
      "RidgeClassifierCV                    0.32  \n",
      "LinearDiscriminantAnalysis           0.55  \n",
      "PassiveAggressiveClassifier          0.20  \n",
      "NearestCentroid                      0.13  \n",
      "QuadraticDiscriminantAnalysis        0.35  \n",
      "GaussianNB                           0.12  \n",
      "DummyClassifier                      0.09  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "\n",
    "        ('model', SVC(\n",
    "                        kernel='linear', \n",
    "                        class_weight='balanced', # penalize\n",
    "                        probability=True\n",
    "                    )\n",
    "        )\n",
    "      \n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[489,  23],\n",
       "       [ 60, 395]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.96      0.92       512\n",
      "         1.0       0.94      0.87      0.90       455\n",
      "\n",
      "    accuracy                           0.91       967\n",
      "   macro avg       0.92      0.91      0.91       967\n",
      "weighted avg       0.92      0.91      0.91       967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try the code on the original split without downsampling to make sure that the model can predict on unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = ml_data.drop(columns='spn_5246')\n",
    "\n",
    "y2 = ml_data['spn_5246']\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=.25, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[130622,   5993],\n",
       "       [    76,    389]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y2_test, pipe.predict(X2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.96      0.98    136615\n",
      "         1.0       0.06      0.84      0.11       465\n",
      "\n",
      "    accuracy                           0.96    137080\n",
      "   macro avg       0.53      0.90      0.55    137080\n",
      "weighted avg       1.00      0.96      0.97    137080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y2_test, pipe.predict(X2_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
